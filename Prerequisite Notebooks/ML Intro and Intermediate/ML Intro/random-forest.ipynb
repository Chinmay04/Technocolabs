{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This notebook is an exercise in the [Introduction to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/random-forests).**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"## Recap\nHere's the code you've written so far."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code you have previously used to load data\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n# Path of the file to read\niowa_file_path = '../input/home-data-for-ml-course/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\n# Create target object and call it y\ny = home_data.SalePrice\n# Create X\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\nX = home_data[features]\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Specify Model\niowa_model = DecisionTreeRegressor(random_state=1)\n# Fit Model\niowa_model.fit(train_X, train_y)\n\n# Make validation predictions and calculate mean absolute error\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n# Using best value for max_leaf_nodes\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\niowa_model.fit(train_X, train_y)\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex6 import *\nprint(\"\\nSetup complete\")","execution_count":1,"outputs":[{"output_type":"stream","text":"Validation MAE when not specifying max_leaf_nodes: 29,653\nValidation MAE for best value of max_leaf_nodes: 27,283\n\nSetup complete\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Exercises\nData science isn't always this easy. But replacing the decision tree with a Random Forest is going to be an easy win."},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Use a Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Define the model. Set random_state to 1\nrf_model = RandomForestRegressor(random_state=1)\n\n# fit your model\nrf_model.fit(train_X,train_y)\n\n# Calculate the mean absolute error of your Random Forest model on the validation data\nrf_val_mae = mean_absolute_error(val_y, rf_model.predict(val_X))\n\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\n\n# Check your answer\nstep_1.check()","execution_count":2,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Expected 2D array, got 1D array instead:\narray=[231500. 179500. 122000.  84500. 142000. 325624. 285000. 151000. 195000.\n 275000. 175000.  61000. 174000. 385000. 230000.  87000. 125000.  98600.\n 260000. 143000. 124000. 122500. 236500. 337500.  76000. 187000. 128000.\n 179000. 485000. 122500. 106000. 118000. 127000.  80000. 153000. 360000.\n 132000.  85500. 262280. 112000. 131000. 139000.  87000. 135000. 181000.\n 163500. 116900. 159895. 244600. 294000.  97000. 295000. 120500. 239500.\n 194000. 115000. 119500. 180000. 118000. 178000. 167000. 267000.  82000.\n 133900. 167000. 132500. 135000. 248000. 160000. 144500. 200500. 113000.\n 354000. 164000. 170000. 224000. 163900. 160000. 466500. 172500. 193500.\n 133000. 137000. 167500. 196500. 146000. 159500. 158000. 189000. 172500.\n 194201. 181000. 115000. 101800. 100000. 139000. 115000. 139000. 156000.\n 158000. 172000. 138000. 125500. 123000. 134500. 163000. 169990. 140000.\n 140000. 325000. 157500. 225000. 107000. 185500. 239900. 163990. 201000.\n 127000. 172500. 228000. 117000. 232600. 403000. 169500. 151400. 180000.\n 370878.  55993. 207500. 224500. 280000.  82000. 137000. 130500.  73000.\n 217000. 625000. 367294. 230000. 142000. 115000. 272000. 176500. 234000.\n  40000. 213500. 126000. 187100. 200000. 117500. 176000. 174000.  97000.\n 169000. 154000. 361919.  85000. 134000.  96500. 127000.  60000. 108480.\n 151000. 135000.  99500. 124000. 177500. 144000. 119000. 107500. 254900.\n 180500. 222000. 271000. 181000. 140000. 158000. 204750. 135000. 161500.\n 128500. 179540. 143000. 147000. 280000. 131500. 253293. 317000. 210000.\n 120000. 110000. 127000. 106000. 172500. 166000. 258000. 213000. 150000.\n 158500.  82500. 212000. 238000. 158000. 178000. 328900. 110000. 185000.\n 320000. 315000. 228950. 180000. 117000. 176000. 111250. 297000. 266000.\n 130000.  93500. 186700.  91000. 745000.  62383. 172500. 170000. 119000.\n 129900. 210000. 173000. 164500. 170000. 125500. 183000. 103000. 141500.\n 315500. 118858. 290000. 119000. 104900. 348000. 374000. 200100. 132250.\n 161500. 131500. 104000. 132500. 133000. 170000. 180000. 130000. 125000.\n 186500. 171500. 100000. 114500. 173000.  86000. 320000. 133000. 220000.\n 137900. 224900. 153500. 115000. 207500. 113000. 178400. 140000.  83000.\n 197000. 187500.  81000.  93500. 197500.  93000. 106000. 144000. 220000.\n 144900. 139000. 132000. 149000. 153500. 263435. 205000. 132500. 103200.\n 249700.  64500.  83000. 339750. 145900. 106250. 164990. 228500. 193000.\n 244000. 159950. 119000. 160000. 147000. 134450. 174000. 144000. 190000.\n 160000. 175000. 135000. 176000. 168500. 139000. 102776. 221500. 148500.\n  55000. 281000. 179900. 182900. 217500. 195000. 154000. 124900. 228000.\n 125000. 438780. 160200. 271000. 113000. 103600. 119500. 275000. 250000.\n 306000. 168000. 136905. 128000. 107000. 341000. 176000. 224900. 289000.\n  79900. 274000. 109900. 175000. 166000. 151000. 264132.  79500. 241000.\n 141000. 377426. 132000. 141000. 136500. 205950. 157000.  93000. 309000.\n 187500. 178000. 125000. 232000. 135000.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a8e6eb9d6e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Calculate the mean absolute error of your Random Forest model on the validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrf_val_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation MAE for Random Forest Model: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_val_mae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    390\u001b[0m                                 X.indptr.dtype != np.intc):\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[231500. 179500. 122000.  84500. 142000. 325624. 285000. 151000. 195000.\n 275000. 175000.  61000. 174000. 385000. 230000.  87000. 125000.  98600.\n 260000. 143000. 124000. 122500. 236500. 337500.  76000. 187000. 128000.\n 179000. 485000. 122500. 106000. 118000. 127000.  80000. 153000. 360000.\n 132000.  85500. 262280. 112000. 131000. 139000.  87000. 135000. 181000.\n 163500. 116900. 159895. 244600. 294000.  97000. 295000. 120500. 239500.\n 194000. 115000. 119500. 180000. 118000. 178000. 167000. 267000.  82000.\n 133900. 167000. 132500. 135000. 248000. 160000. 144500. 200500. 113000.\n 354000. 164000. 170000. 224000. 163900. 160000. 466500. 172500. 193500.\n 133000. 137000. 167500. 196500. 146000. 159500. 158000. 189000. 172500.\n 194201. 181000. 115000. 101800. 100000. 139000. 115000. 139000. 156000.\n 158000. 172000. 138000. 125500. 123000. 134500. 163000. 169990. 140000.\n 140000. 325000. 157500. 225000. 107000. 185500. 239900. 163990. 201000.\n 127000. 172500. 228000. 117000. 232600. 403000. 169500. 151400. 180000.\n 370878.  55993. 207500. 224500. 280000.  82000. 137000. 130500.  73000.\n 217000. 625000. 367294. 230000. 142000. 115000. 272000. 176500. 234000.\n  40000. 213500. 126000. 187100. 200000. 117500. 176000. 174000.  97000.\n 169000. 154000. 361919.  85000. 134000.  96500. 127000.  60000. 108480.\n 151000. 135000.  99500. 124000. 177500. 144000. 119000. 107500. 254900.\n 180500. 222000. 271000. 181000. 140000. 158000. 204750. 135000. 161500.\n 128500. 179540. 143000. 147000. 280000. 131500. 253293. 317000. 210000.\n 120000. 110000. 127000. 106000. 172500. 166000. 258000. 213000. 150000.\n 158500.  82500. 212000. 238000. 158000. 178000. 328900. 110000. 185000.\n 320000. 315000. 228950. 180000. 117000. 176000. 111250. 297000. 266000.\n 130000.  93500. 186700.  91000. 745000.  62383. 172500. 170000. 119000.\n 129900. 210000. 173000. 164500. 170000. 125500. 183000. 103000. 141500.\n 315500. 118858. 290000. 119000. 104900. 348000. 374000. 200100. 132250.\n 161500. 131500. 104000. 132500. 133000. 170000. 180000. 130000. 125000.\n 186500. 171500. 100000. 114500. 173000.  86000. 320000. 133000. 220000.\n 137900. 224900. 153500. 115000. 207500. 113000. 178400. 140000.  83000.\n 197000. 187500.  81000.  93500. 197500.  93000. 106000. 144000. 220000.\n 144900. 139000. 132000. 149000. 153500. 263435. 205000. 132500. 103200.\n 249700.  64500.  83000. 339750. 145900. 106250. 164990. 228500. 193000.\n 244000. 159950. 119000. 160000. 147000. 134450. 174000. 144000. 190000.\n 160000. 175000. 135000. 176000. 168500. 139000. 102776. 221500. 148500.\n  55000. 281000. 179900. 182900. 217500. 195000. 154000. 124900. 228000.\n 125000. 438780. 160200. 271000. 113000. 103600. 119500. 275000. 250000.\n 306000. 168000. 136905. 128000. 107000. 341000. 176000. 224900. 289000.\n  79900. 274000. 109900. 175000. 166000. 151000. 264132.  79500. 241000.\n 141000. 377426. 132000. 141000. 136500. 205950. 157000.  93000. 309000.\n 187500. 178000. 125000. 232000. 135000.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."]}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# The lines below will show you a hint or the solution.\n# step_1.hint() \n# step_1.solution()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, you have followed specific instructions at each step of your project. This helped learn key ideas and build your first model, but now you know enough to try things on your own. \n\nMachine Learning competitions are a great way to try your own ideas and learn more as you independently navigate a machine learning project. \n\n# Keep Going\n\nYou are ready for **[Machine Learning Competitions](https://www.kaggle.com/dansbecker/machine-learning-competitions).**\n"},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161285) to chat with other Learners.*"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}